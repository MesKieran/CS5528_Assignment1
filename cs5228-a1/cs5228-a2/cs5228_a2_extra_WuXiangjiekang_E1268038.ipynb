{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763f0fa0-6584-44d4-b163-a891252769f9",
   "metadata": {},
   "source": [
    "# CS5228 Assignment 2 Extra\n",
    "\n",
    "Hello everyone, this assignment notebook covers Clustering using question-answering tasks. For the answers, you can refer to [this Markdown guide](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd) to customize the layout (although it shouldn't be needed).\n",
    "\n",
    "**Important:** \n",
    "* Rename and save this Jupyter notebook as **cs5228_a2_extra_YourName_YourNUSNETID.ipynb** (e.g., **cs5228_a2_BobSmith_e12345678.ipynb**) before submission!\n",
    "* Submission deadline is Sep 28, 11.59 pm. Late submissions will be penalized by 10% for each additional day. Failure to appropriately rename both files will yield a penalty of 1 Point. There is no need to use your full name if its a rather long; it's just  important to easily identify you in Canvas etc.\n",
    "\n",
    "Please also add your NUSNET and student id in the code cell below. This is just to make any identification of your notebook doubly sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119a3b10-7afe-4814-9a79-32310842f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'A0286970M'\n",
    "nusnet_id = 'E1268038'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7455d1c-31ad-4620-8d8a-ad2adc363f56",
   "metadata": {},
   "source": [
    "Here is an overview over the tasks to be solved and the points associated with each task. The notebook can appear very long and verbose, but note that a lot of parts provide additional explanations, documentation, or some discussion. The code and markdown cells you are supposed to complete are well, but you can use the overview below to double-check that you covered everything.\n",
    "\n",
    "* **4 Questions about Clustering (5 Points)**\n",
    "    * 4.1 DBSCAN on Scaled Data (2 Points)\n",
    "    * 4.2 K-Means++ with Deterministic Result (3 Points)Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ccaa8-0df8-4b2c-9676-0f872ec645d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65ca2e-36ac-4d5e-aa5d-b5c5e39ba1a4",
   "metadata": {},
   "source": [
    "## 4 Questions about Clustering (5 Points)\n",
    "\n",
    "### 4.1 DBSCAN on Scaled Data (2 Points)\n",
    "\n",
    "Assume you have a $d$-dimensional dataset `X` in the Euclidean space, i.e., each data point as $d$ numerical features (with each feature value in the interval $[0, 1]$). After running DBSCAN over `X`, you get some clustering (again, we only assume it's not only noise). Now you create a new dataset `X_new` by multiplying all data points by 10 afterwards adding 100 to all data points (in Python, assuming X is a NumPy array this can simply be done by `X_new = X * 10 + 100`). Now you can run DBSCAN over `X_new`.\n",
    "\n",
    "**Explain how you have to change the parameters of DBSCAN for `X_new` to get the same clusters as for `X`!**. You can ignore any corner cases like duplicate data points or the case where all the data points are noise points.\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45047a8-929e-430a-9eb0-dd5ed9e11af9",
   "metadata": {},
   "source": [
    "**Adjust Epsilon (eps):**\n",
    "\n",
    "We should set eps_new = eps_original * 10, sSince we scaled the data by multiplying all data points by 10 and adding 100, the distances between data points in X_new will be larger than in X.We don't need to care about the +100 since all the points will be moved uniformly..ion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4b827",
   "metadata": {},
   "source": [
    "### 4.2 K-Means++ with Deterministic Result (3 Points)\n",
    "\n",
    "Assume you have a $d$-dimensional dataset `X` in the Euclidean space, i.e., each data point as $d$ numerical features (with each feature value in the interval $[0, 1]$). You have 1,000 data points in total. Now you run K-Means with K-Means++ initialization and a value of K=20, yielding a clustering of 20 non-empty clusters.\n",
    "\n",
    "**Describe a data distribution of `X` where you will always get the same clustering when running K-Means++ with K=20!**. In other words, you run K-Means++ with K=20 again and again over X, and you will always get the same clustering. How must `X` \"look\" like to guarantee that?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeba51a",
   "metadata": {},
   "source": [
    "1.Same Initial Centroid Positions:The initial positions of the K-means++ centroids should be the same in each run. This can be ensured by keeping the initializations of centroids constant across runs.\n",
    "\n",
    "2.Perfect Separation:\n",
    "Each of the 20 clusters in X should be well-separated from one another, with clear and distinct boundaries. There should be no data points that are close to or shared between multiple clusters. This perfect separation ensures that K-Means++ will consistently assign each data point to its nearest cluster centroid\n",
    "\n",
    "3.\n",
    "\r\n",
    "No Outiers:\r\n",
    "There should be no outliers or noise points that are far away from any , as they will affect the clustering process.ross runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
